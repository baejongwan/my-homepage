# -*- coding: utf-8 -*-
"""
LUMI ìê¸° í•™ìŠµ ì‹œìŠ¤í…œ
ìˆ˜ì§‘ëœ ë°ì´í„°ë¡œ ì „ëµ ìë™ ê°œì„ 
"""
import sys
sys.stdout.reconfigure(encoding='utf-8')

import json
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
from collections import deque
import statistics

class SelfLearningSystem:
    """ìê°€ í•™ìŠµ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.data_dir = Path("logs") / "collected_data"
        self.learning_file = self.data_dir / "learning_data.json"
        self.insights_file = self.data_dir / "strategy_insights.json"
        self.thesis_file = self.data_dir / "trading_thesis.md"
        
        # í•™ìŠµ ë°ì´í„° êµ¬ì¡°
        self.learning_data = {
            'optimal_entry_rsi': {'long': [], 'short': []},
            'optimal_bb_pct': {'long': [], 'short': []},
            'optimal_volume_ratio': [],
            'best_exit_timing': [],
            'market_regime_performance': {},
            'time_based_patterns': {},
            'day_of_week_stats': {},
            'hourly_win_rates': {}
        }
        
        self.min_samples = 10  # í•™ìŠµì— í•„ìš”í•œ ìµœì†Œ ìƒ˜í”Œ ìˆ˜
        self.recent_trades_window = 50  # ìµœê·¼ ê±°ë˜ ë¶„ì„ ìœˆë„ìš°
    
    def load_trade_history(self):
        """ê±°ë˜ ì´ë ¥ ë¡œë“œ"""
        try:
            files = list(self.data_dir.glob("trade_analysis_*.csv"))
            all_trades = []
            
            for f in files:
                df = pd.read_csv(f)
                all_trades.append(df)
            
            if all_trades:
                return pd.concat(all_trades, ignore_index=True)
            return None
        except Exception as e:
            print(f"ê±°ë˜ ì´ë ¥ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return None
    
    def load_price_data(self, hours=168):
        """ê°€ê²© ë°ì´í„° ë¡œë“œ (ê¸°ë³¸: 7ì¼)"""
        try:
            files = list(self.data_dir.glob("price_data_*.csv"))
            all_data = []
            
            for f in files:
                df = pd.read_csv(f)
                df['timestamp'] = pd.to_datetime(df['timestamp'])
                all_data.append(df)
            
            if all_data:
                combined = pd.concat(all_data, ignore_index=True)
                # ìµœê·¼ Nì‹œê°„ë§Œ
                cutoff = datetime.now() - timedelta(hours=hours)
                return combined[combined['timestamp'] > cutoff]
            return None
        except Exception as e:
            print(f"ê°€ê²© ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
            return None
    
    def learn_from_trades(self):
        """ê±°ë˜ ë°ì´í„°ë¡œë¶€í„° í•™ìŠµ"""
        df = self.load_trade_history()
        if df is None or len(df) < self.min_samples:
            print(f"âš ï¸ í•™ìŠµ ë°ì´í„° ë¶€ì¡± (í˜„ì¬: {len(df) if df is not None else 0}, í•„ìš”: {self.min_samples})")
            return None
        
        print(f"ğŸ“š {len(df)}ê°œ ê±°ë˜ ë°ì´í„°ë¡œ í•™ìŠµ ì¤‘...")
        
        insights = {
            'generated_at': datetime.now().isoformat(),
            'total_samples': len(df),
            'learning_results': {}
        }
        
        # 1. ë¡± ì§„ì… ìµœì  ì¡°ê±´ í•™ìŠµ
        winners = df[df['pnl'] > 0]
        
        if len(winners) > 0:
            # ë¡± ì„±ê³µ ì¡°ê±´
            long_winners = winners[winners['type'] == 'LONG']
            if len(long_winners) > 0:
                insights['learning_results']['optimal_long_entry'] = {
                    'rsi_range': f"{long_winners['entry_rsi'].quantile(0.25):.1f} ~ {long_winners['entry_rsi'].quantile(0.75):.1f}",
                    'rsi_mean': long_winners['entry_rsi'].mean(),
                    'rsi_std': long_winners['entry_rsi'].std(),
                    'bb_pct_range': f"{long_winners['entry_bb_pct'].quantile(0.25):.2f} ~ {long_winners['entry_bb_pct'].quantile(0.75):.2f}",
                    'bb_pct_mean': long_winners['entry_bb_pct'].mean(),
                    'avg_duration': long_winners['duration_seconds'].mean(),
                    'best_exit_reason': long_winners['exit_reason'].mode()[0] if len(long_winners['exit_reason'].mode()) > 0 else 'unknown'
                }
            
            # ìˆ ì„±ê³µ ì¡°ê±´
            short_winners = winners[winners['type'] == 'SHORT']
            if len(short_winners) > 0:
                insights['learning_results']['optimal_short_entry'] = {
                    'rsi_range': f"{short_winners['entry_rsi'].quantile(0.25):.1f} ~ {short_winners['entry_rsi'].quantile(0.75):.1f}",
                    'rsi_mean': short_winners['entry_rsi'].mean(),
                    'bb_pct_range': f"{short_winners['entry_bb_pct'].quantile(0.25):.2f} ~ {short_winners['entry_bb_pct'].quantile(0.75):.2f}",
                    'bb_pct_mean': short_winners['entry_bb_pct'].mean(),
                    'avg_duration': short_winners['duration_seconds'].mean()
                }
        
        # 2. ì‹œê°„ëŒ€ë³„ íŒ¨í„´
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df['hour'] = df['timestamp'].dt.hour
        df['day_of_week'] = df['timestamp'].dt.dayofweek  # 0=ì›”, 6=ì¼
        
        hourly_stats = df.groupby('hour').agg({
            'pnl': ['count', 'mean', 'sum'],
            'type': lambda x: (x == 'LONG').sum() / len(x) * 100
        }).reset_index()
        hourly_stats.columns = ['hour', 'trade_count', 'avg_pnl', 'total_pnl', 'long_ratio']
        
        best_hours = hourly_stats[hourly_stats['trade_count'] >= 3].nlargest(3, 'avg_pnl')
        insights['learning_results']['best_trading_hours'] = best_hours.to_dict('records')
        
        # 3. ìš”ì¼ë³„ íŒ¨í„´
        dow_names = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
        dow_stats = df.groupby('day_of_week').agg({
            'pnl': ['count', 'mean', 'sum']
        }).reset_index()
        dow_stats.columns = ['day', 'trade_count', 'avg_pnl', 'total_pnl']
        dow_stats['day_name'] = dow_stats['day'].apply(lambda x: dow_names[int(x)])
        
        best_days = dow_stats[dow_stats['trade_count'] >= 3].nlargest(3, 'avg_pnl')
        insights['learning_results']['best_trading_days'] = best_days.to_dict('records')
        
        # 4. ì‹œì¥ í™˜ê²½ë³„ ì„±ê³¼
        if 'market_regime' in df.columns:
            regime_stats = df.groupby('market_regime').agg({
                'pnl': ['count', 'mean', 'sum'],
                'mode': lambda x: x.mode()[0] if len(x.mode()) > 0 else 'unknown'
            }).reset_index()
            insights['learning_results']['regime_performance'] = regime_stats.to_dict('records')
        
        # 5. ëª¨ë“œë³„ ìµœì í™”
        mode_stats = df.groupby('mode').agg({
            'pnl': ['count', 'mean'],
            'exit_reason': lambda x: x.mode()[0]
        }).reset_index()
        mode_stats.columns = ['mode', 'trade_count', 'avg_pnl', 'common_exit']
        insights['learning_results']['mode_optimization'] = mode_stats.to_dict('records')
        
        # 6. ë‚˜ìœ ì§„ì… í”¼í•˜ê¸°
        losers = df[df['pnl'] <= 0]
        if len(losers) > 0:
            bad_entries = {
                'avg_rsi': losers['entry_rsi'].mean(),
                'rsi_range': f"{losers['entry_rsi'].min():.1f} ~ {losers['entry_rsi'].max():.1f}",
                'avg_bb_pct': losers['entry_bb_pct'].mean(),
                'common_sl': len(losers[losers['exit_reason'] == 'SL']) / len(losers) * 100
            }
            insights['learning_results']['avoid_these_conditions'] = bad_entries
        
        # JSONìœ¼ë¡œ ì €ì¥
        with open(self.insights_file, 'w', encoding='utf-8') as f:
            json.dump(insights, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"âœ… í•™ìŠµ ì™„ë£Œ! ì¸ì‚¬ì´íŠ¸ ì €ì¥: {self.insights_file}")
        return insights
    
    def generate_trading_thesis(self):
        """í•™ìŠµëœ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ íŠ¸ë ˆì´ë”© ë…¼ë¬¸ ì‘ì„±"""
        insights = self.learn_from_trades()
        if insights is None:
            return None
        
        results = insights.get('learning_results', {})
        
        markdown = f"""# ë£¨ë¯¸ì˜ íŠ¸ë ˆì´ë”© ë…¼ë¬¸
## ìë™ ìƒì„±ë¨: {datetime.now().strftime('%Y-%m-%d %H:%M')}

### ğŸ“Š í•™ìŠµ ë°ì´í„° ìš”ì•½
- ì´ ê±°ë˜ ìˆ˜: {insights.get('total_samples', 0)}íšŒ
- ë¶„ì„ ê¸°ê°„: ìµœê·¼ {self.recent_trades_window}íšŒ ì¤‘ì‹¬

---

### ğŸ¯ ìµœì  ë¡± ì§„ì… ì¡°ê±´
"""
        
        if 'optimal_long_entry' in results:
            long_opt = results['optimal_long_entry']
            markdown += f"""
```
RSI: {long_opt.get('rsi_range', 'N/A')} (í‰ê· : {long_opt.get('rsi_mean', 0):.1f})
BB%: {long_opt.get('bb_pct_range', 'N/A')} (í‰ê· : {long_opt.get('bb_pct_mean', 0):.2f})
í‰ê·  ë³´ìœ ì‹œê°„: {long_opt.get('avg_duration', 0)/60:.1f}ë¶„
ìµœê³  ì²­ì‚°: {long_opt.get('best_exit_reason', 'unknown')}
```
"""
        
        markdown += "\n### ğŸ“‰ ìµœì  ìˆ ì§„ì… ì¡°ê±´\n"
        if 'optimal_short_entry' in results:
            short_opt = results['optimal_short_entry']
            markdown += f"""
```
RSI: {short_opt.get('rsi_range', 'N/A')} (í‰ê· : {short_opt.get('rsi_mean', 0):.1f})
BB%: {short_opt.get('bb_pct_range', 'N/A')} (í‰ê· : {short_opt.get('bb_pct_mean', 0):.2f})
í‰ê·  ë³´ìœ ì‹œê°„: {short_opt.get('avg_duration', 0)/60:.1f}ë¶„
```
"""
        
        markdown += "\n### â° ìµœê³ ì˜ ê±°ë˜ ì‹œê°„ëŒ€\n"
        if 'best_trading_hours' in results:
            for hour_data in results['best_trading_hours']:
                markdown += f"- **{int(hour_data['hour'])}ì‹œ**: í‰ê·  {hour_data['avg_pnl']:+.2f}$ ({int(hour_data['trade_count'])}íšŒ)\n"
        
        markdown += "\n### ğŸ“… ìš”ì¼ë³„ ì„±ê³¼\n"
        if 'best_trading_days' in results:
            for day_data in results['best_trading_days']:
                markdown += f"- **{day_data['day_name']}ìš”ì¼**: í‰ê·  {day_data['avg_pnl']:+.2f}$ ({int(day_data['trade_count'])}íšŒ)\n"
        
        markdown += "\n### âš ï¸ í”¼í•´ì•¼ í•  ì¡°ê±´\n"
        if 'avoid_these_conditions' in results:
            avoid = results['avoid_these_conditions']
            markdown += f"""
```
í‰ê·  RSI: {avoid.get('avg_rsi', 0):.1f}
RSI ë²”ìœ„: {avoid.get('rsi_range', 'N/A')}
SL ë¹„ìœ¨: {avoid.get('common_sl', 0):.1f}%
```
â†’ ì´ëŸ° ì¡°ê±´ì—ì„œëŠ” ì§„ì… ìì œ!
"""
        
        markdown += f"""
---

### ğŸ’¡ ë£¨ë¯¸ì˜ ì œì•ˆ
"""
        
        # ìë™ ì œì•ˆ ìƒì„±
        recommendations = self._auto_recommendations(results)
        for rec in recommendations:
            markdown += f"- {rec}\n"
        
        markdown += f"""
---

### ğŸ”„ ë‹¤ìŒ ì—…ë°ì´íŠ¸
- ë§¤ 20íšŒ ê±°ë˜ë§ˆë‹¤ ìë™ ì—…ë°ì´íŠ¸
- ë‹¤ìŒ ì—…ë°ì´íŠ¸ ì˜ˆì •: {len(insights.get('total_samples', 0)) if insights else 'N/A'}íšŒ ì´í›„

*ì´ ë¬¸ì„œëŠ” ìˆ˜ì§‘ëœ ì‹¤ì „ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìë™ ìƒì„±ë¨*
"""
        
        # íŒŒì¼ ì €ì¥
        with open(self.thesis_file, 'w', encoding='utf-8') as f:
            f.write(markdown)
        
        print(f"âœ… íŠ¸ë ˆì´ë”© ë…¼ë¬¸ ìƒì„±: {self.thesis_file}")
        return self.thesis_file
    
    def _auto_recommendations(self, results):
        """ìë™ ì œì•ˆ ìƒì„±"""
        recs = []
        
        if 'avoid_these_conditions' in results:
            avoid = results['avoid_these_conditions']
            common_sl = avoid.get('common_sl', 0)
            if common_sl > 60:
                recs.append("ğŸš¨ SL ë¹„ìœ¨ì´ 60% ì´ˆê³¼ - ì§„ì… ì¡°ê±´ì„ ë” ì—„ê²©íˆ í•˜ì„¸ìš”")
        
        if 'mode_optimization' in results:
            for mode_data in results['mode_optimization']:
                if mode_data.get('avg_pnl', 0) > 0:
                    recs.append(f"âœ… {mode_data['mode']} ëª¨ë“œ ìˆ˜ìµ ì¤‘ - ë¹„ì¤‘ í™•ëŒ€ ê²€í† ")
                else:
                    recs.append(f"âš ï¸ {mode_data['mode']} ëª¨ë“œ ì†ì‹¤ ì¤‘ - ì¡°ê±´ ì¬ê²€í†  í•„ìš”")
        
        if len(recs) == 0:
            recs.append("ğŸ“Š ë” ë§ì€ ê±°ë˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤ (ìµœì†Œ 20íšŒ ê¶Œì¥)")
        
        return recs
    
    def suggest_parameter_changes(self):
        """íŒŒë¼ë¯¸í„° ë³€ê²½ ì œì•ˆ"""
        df = self.load_trade_history()
        if df is None or len(df) < 15:
            return None
        
        suggestions = []
        
        # SL/TP ìµœì í™”
        sl_hits = len(df[df['exit_reason'] == 'SL'])
        tp_hits = len(df[df['exit_reason'] == 'TP'])
        total = len(df)
        
        sl_ratio = sl_hits / total
        tp_ratio = tp_hits / total
        
        if sl_ratio > 0.7:
            suggestions.append({
                'parameter': 'SL_PERCENT',
                'current': 0.012,
                'suggested': 0.015,
                'reason': f'SL ë¹„ìœ¨ {sl_ratio*100:.1f}% - ë„ˆë¬´ ë¹¨ë¦¬ ì†ì ˆ ì¤‘'
            })
        
        if tp_ratio > 0.6:
            suggestions.append({
                'parameter': 'TP_PERCENT',
                'current': 0.025,
                'suggested': 0.020,
                'reason': f'TP ë¹„ìœ¨ {tp_ratio*100:.1f}% - ìˆ˜ìµ ì‹¤í˜„ì´ ë¹ ë¦„, ë” ë¹¨ë¦¬ í™•ë³´'
            })
        
        # RSI ì„ê³„ê°’ ì¡°ì •
        long_winners = df[(df['type'] == 'LONG') & (df['pnl'] > 0)]
        if len(long_winners) > 5:
            avg_entry_rsi = long_winners['entry_rsi'].mean()
            if avg_entry_rsi > 35:  # RSI 30ë³´ë‹¤ ë†’ê²Œ ì„±ê³µ
                suggestions.append({
                    'parameter': 'RSI_LONG_THRESHOLD',
                    'current': 30,
                    'suggested': int(avg_entry_rsi),
                    'reason': f'ì„±ê³µí•œ ë¡±ì˜ í‰ê·  ì§„ì… RSI: {avg_entry_rsi:.1f}'
                })
        
        return suggestions


if __name__ == "__main__":
    learner = SelfLearningSystem()
    
    # í•™ìŠµ ì‹¤í–‰
    insights = learner.learn_from_trades()
    
    if insights:
        # ë…¼ë¬¸ ìƒì„±
        thesis = learner.generate_trading_thesis()
        print(f"\nâœ… í•™ìŠµ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print(f"   ë…¼ë¬¸: {thesis}")
